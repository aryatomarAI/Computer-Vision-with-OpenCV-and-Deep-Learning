{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Flow \n",
    "**Optical flow is the pattern of apparent motion of image object between two consecutive frames cause by the movement of object or camera**\n",
    "\n",
    "* Optical flow analysis has few assumptions:\n",
    "    \n",
    "    1. The pixel intensities of an object do not change between consecutive frames.\n",
    "    \n",
    "    2. Neighbors pixels have similar motion.\n",
    "    \n",
    "    3. The optical flow methods in OpenCV will first take in a given set of points and a frame.\n",
    "    \n",
    "    4. Then it will attempt to find those points in the next frame.\n",
    "    \n",
    "    5. It is upto the user to supply the points to track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanada\n",
    "Lucas-Kanada is a function used in Object tracking.\n",
    "\n",
    "Using OpenCV we pass in the previous frame, previous points and the current frame to the Lucas-Kanada Function.\n",
    "\n",
    "The Lucas-Kanada computes Optical flow for a sparse feature set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But what if we want to track all the points in a video?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gunner Farneback's Algorithm\n",
    "\n",
    "* We can use Gunner Farnback's algorithm(also built-in to OpenCV) to calculate dense optical flow.\n",
    "\n",
    "* This dense optical flow will calculate flow for all the points in an image.\n",
    "\n",
    "* It will color them black if no flow(no movement is detected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucas-Kanada Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corner tracking parameter dictionary\n",
    "corner_track_params=dict(maxCorners=10,qualityLevel=0.3,minDistance=7,blockSize=7)\n",
    "\n",
    "#lucas-kanada parameters dictionary\n",
    "lk_params=dict(winSize=(200,200),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "# 1st Frame that will act as the previous frame to the current frame\n",
    "\n",
    "ret,prev_frame=cap.read()\n",
    "\n",
    "# Turn this frame to gray scale\n",
    "prev_gray=cv2.cvtColor(prev_frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Points to track\n",
    "\n",
    "prevPts=cv2.goodFeaturesToTrack(prev_gray,mask=None,**corner_track_params)\n",
    "\n",
    "mask=np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    # Current frame\n",
    "    ret, frame=cap.read()\n",
    "    \n",
    "    # Convert frame to gray scale \n",
    "    \n",
    "    frame_gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the Optical flow  ()\n",
    "    \n",
    "    nextPts, status, err= cv2.calcOpticalFlowPyrLK(prev_gray,frame_gray,prevPts,None,**lk_params)\n",
    "    \n",
    "    # Status array will give vectors in output vector is set to 1 if any motion is detected between the two frames\n",
    "    \n",
    "    good_new=nextPts[status==1]\n",
    "    good_prev=prevPts[status==1]\n",
    "    \n",
    "    for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "        x_new,y_new=new.ravel()\n",
    "        x_prev,y_prev=prev.ravel()\n",
    "        \n",
    "        # draw green lines between points in changed frames after apparent motion\n",
    "        mask=cv2.line(mask,(x_new,y_new),(x_prev,y_prev),(0,255,0),3)\n",
    "        \n",
    "        frame=cv2.circle(frame,(x_new,y_new),6,(0,255,0),-1)\n",
    "        \n",
    "        \n",
    "    img=cv2.add(frame,mask)\n",
    "    \n",
    "    cv2.imshow('tracking',img)\n",
    "    \n",
    "    k=cv2.waitKey(20) & 0xFF\n",
    "    if k==27:\n",
    "        break\n",
    "    \n",
    "    # updating frames and previous points\n",
    "    prev_gray=frame_gray.copy()\n",
    "    prevPts=good_new.reshape(-1,1,2)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will use Gunner Farneback's Algo for Dense Optical Flow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "* prev : First input image in 8-bit single channel format.\n",
    "    \n",
    "* next : Second input image of same type and same size as prev.\n",
    "    \n",
    "* pyr_scale : parameter specifying the image scale to build pyramids for each image (scale < 1). A classic pyramid is of generally 0.5 scale, every new layer added, it is halved to the previous one.\n",
    "    \n",
    "* levels : levels=1 says, there are no extra layers (only the initial image) . It is the number of pyramid layers including the first image.\n",
    "    \n",
    "* winsize : It is the average window size, larger the size, the more robust the algorithm is to noise, and provide fast motion detection, though gives blurred motion fields.\n",
    "    \n",
    "* iterations : Number of iterations to be performed at each pyramid level.\n",
    "    \n",
    "* poly_n : It is typically 5 or 7, it is the size of the pixel neighbourhood which is used to find polynomial expansion between the pixels.\n",
    "    \n",
    "* poly_sigma : standard deviation of the gaussian that is for derivatives to be smooth as the basis of the polynomial expansion. It can be 1.1 for poly= 5 and 1.5 for poly= 7.\n",
    "    \n",
    "* flow : computed flow image that has similar size as prev and type to be CV_32FC2.\n",
    "    \n",
    "* flags : It can be a combination of:\n",
    "        \n",
    "    1. OPTFLOW_USE_INITIAL_FLOW uses input flow as initial apporximation.\n",
    "    \n",
    "    2. OPTFLOW_FARNEBACK_GAUSSIAN uses gaussian winsize*winsize filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "ret,frame1=cap.read()\n",
    "\n",
    "prev_img=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv_mask=np.zeros_like(frame1)\n",
    "\n",
    "# Grab the saturation and assign highest saturation to the  mask\n",
    "hsv_mask[:,:,1]=255\n",
    "\n",
    "while True:\n",
    "    ret,frame2=cap.read()\n",
    "    \n",
    "    next_img=cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # use gunner algo to find optical flow\n",
    "    flow=cv2.calcOpticalFlowFarneback(prev_img,next_img,None,0.5,3,15,3,5,1.2,0)\n",
    "    \n",
    "    #After this fuction we have flow object as an output which contains vector flow cartesian information.\n",
    "    # And we need to convert this output into magnitude and angle\n",
    "    \n",
    "    mag,ang=cv2.cartToPolar(flow[:,:,0],flow[:,:,1],angleInDegrees=True)\n",
    "    \n",
    "    hsv_mask[:,:,0]=ang/2\n",
    "    hsv_mask[:,:,2]=cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    bgr=cv2.cvtColor(hsv_mask,cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv2.imshow('frame',bgr)\n",
    "    \n",
    "    k=cv2.waitKey(20) & 0xFF\n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "    prev_img=next_img\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
