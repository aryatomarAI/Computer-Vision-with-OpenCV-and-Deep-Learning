{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Flow \n",
    "**Optical flow is the pattern of apparent motion of image object between two consecutive frames cause by the movement of object or camera**\n",
    "\n",
    "* Optical flow analysis has few assumptions:\n",
    "    \n",
    "    1. The pixel intensities of an object do not change between consecutive frames.\n",
    "    \n",
    "    2. Neighbors pixels have similar motion.\n",
    "    \n",
    "    3. The optical flow methods in OpenCV will first take in a given set of points and a frame.\n",
    "    \n",
    "    4. Then it will attempt to find those points in the next frame.\n",
    "    \n",
    "    5. It is upto the user to supply the points to track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanada\n",
    "Lucas-Kanada is a function used in Object tracking.\n",
    "\n",
    "Using OpenCV we pass in the previous frame, previous points and the current frame to the Lucas-Kanada Function.\n",
    "\n",
    "The Lucas-Kanada computes Optical flow for a sparse feature set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But what if we want to track all the points in a video?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gunner Farneback's Algorithm\n",
    "\n",
    "* We can use Gunner Farnback's algorithm(also built-in to OpenCV) to calculate dense optical flow.\n",
    "\n",
    "* This dense optical flow will calculate flow for all the points in an image.\n",
    "\n",
    "* It will color them black if no flow(no movement is detected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucas-Kanada Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corner tracking parameter dictionary\n",
    "corner_track_params=dict(maxCorners=10,qualityLevel=0.3,minDistance=7,blockSize=7)\n",
    "\n",
    "#lucas-kanada parameters dictionary\n",
    "lk_params=dict(winSize=(200,200),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "# 1st Frame that will act as the previous frame to the current frame\n",
    "\n",
    "ret,prev_frame=cap.read()\n",
    "\n",
    "# Turn this frame to gray scale\n",
    "prev_gray=cv2.cvtColor(prev_frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Points to track\n",
    "\n",
    "prevPts=cv2.goodFeaturesToTrack(prev_gray,mask=None,**corner_track_params)\n",
    "\n",
    "mask=np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    # Current frame\n",
    "    ret, frame=cap.read()\n",
    "    \n",
    "    # Convert frame to gray scale \n",
    "    \n",
    "    frame_gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the Optical flow  ()\n",
    "    \n",
    "    nextPts, status, err= cv2.calcOpticalFlowPyrLK(prev_gray,frame_gray,prevPts,None,**lk_params)\n",
    "    \n",
    "    # Status array will give vectors in output vector is set to 1 if any motion is detected between the two frames\n",
    "    \n",
    "    good_new=nextPts[status==1]\n",
    "    good_prev=prevPts[status==1]\n",
    "    \n",
    "    for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "        x_new,y_new=new.ravel()\n",
    "        x_prev,y_prev=prev.ravel()\n",
    "        \n",
    "        # draw green lines between points in changed frames after apparent motion\n",
    "        mask=cv2.line(mask,(x_new,y_new),(x_prev,y_prev),(0,255,0),3)\n",
    "        \n",
    "        frame=cv2.circle(frame,(x_new,y_new),6,(0,255,0),-1)\n",
    "        \n",
    "        \n",
    "    img=cv2.add(frame,mask)\n",
    "    \n",
    "    cv2.imshow('tracking',img)\n",
    "    \n",
    "    k=cv2.waitKey(20) & 0xFF\n",
    "    if k==27:\n",
    "        break\n",
    "    \n",
    "    # updating frames and previous points\n",
    "    prev_gray=frame_gray.copy()\n",
    "    prevPts=np.float32(good_new).reshape(-1,1,2)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
