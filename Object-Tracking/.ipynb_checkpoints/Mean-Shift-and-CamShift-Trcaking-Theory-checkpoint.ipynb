{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Shift and Cam Shift Tracking\n",
    "\n",
    "Mean shift and cam shift methods are most basic methods of tracking.\n",
    "\n",
    "**Mean Shift**\n",
    "\n",
    "* Imagine if  we have a set of points and we wanted to assign them into clusters.\n",
    "\n",
    "* Then we take all our data points and stack red and blue points on them.\n",
    "\n",
    "* The direction to the closest cluster centroid is determined by where most of the points nearby at.\n",
    "\n",
    "* So each iteration each blue point will move closer to where the most points are at, which is or will lead to the cluster center.\n",
    "\n",
    "**Drawback of meanshift**\n",
    "\n",
    "It won't always detect clusters properly, what may be more reasonable\n",
    "\n",
    "**How Mean shift is helpful in object tracking**\n",
    "\n",
    "Mean Shift can be given a target to track, calculate the color histogram of the target area, and then keep sliding the tracking window to the tracking window to the closest match(the cluster center)\n",
    "\n",
    "**Just using Mean Shift won't change the window size if the target moves away or towards the camera.**\n",
    "\n",
    "* In that case we can use CAM Shift to update the size of the window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Tracking using Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the needed modules\n",
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the webcam frames\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "# first frame\n",
    "ret,frame1=cap.read()\n",
    "\n",
    "# In our case we will detect the face and then track it \n",
    "face_cascade=cv2.CascadeClassifier('C:/Users/DELL/Desktop/Computer-Vision-with-OpenCV-and-Deep-Learning/Object-Detection-with-OpenCV/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_img=frame1.copy()\n",
    "face_rects=face_cascade.detectMultiScale(face_img)\n",
    "\n",
    "# We want to track only a single face \n",
    "(face_x,face_y,w,h)=tuple(face_rects[0])\n",
    "\n",
    "trac_window=(face_x,face_y,w,h)\n",
    "    \n",
    "\n",
    "# Our region of interest\n",
    "roi=face_img[face_y : face_y+h, face_x : face_x+w]\n",
    "\n",
    "# Convert roi's color scale to hsv\n",
    "\n",
    "hsv_roi=cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# For back tracking our window we have to first grab the color histogram of the roi\n",
    "\n",
    "roi_hist=cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n",
    "\n",
    "# Normalise the hist roi \n",
    "roi_hist=cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Our termination criteria \n",
    "term_criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_EPS,10,1)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    # Convert the farme scheme to hsv scale\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Back tracking our window\n",
    "    dst=cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "    \n",
    "    # Track detected face window\n",
    "    ret,track_window=cv2.meanShift(dst,trac_window,term_criteria)\n",
    "    \n",
    "    x,y,w,h=track_window\n",
    "    \n",
    "    img2=cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),5)\n",
    "    \n",
    "    cv2.imshow('img',img2)\n",
    "    \n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Object Tracking with CAM Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "ret,frame1=cap.read()\n",
    "\n",
    "face_cascade=cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "face_rects=face_cascade.detectMultiScale(frame1)\n",
    "\n",
    "(face_x,face_y,w,h)=tuple(face_rects[0])\n",
    "\n",
    "track_window=(face_x,face_y,w,h)\n",
    "\n",
    "roi=frame1[face_y:face_y + h, face_x:face_x +w]\n",
    "\n",
    "hsv_roi=cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "roi_hist=cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n",
    "\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "term_crit=( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT , 10, 1)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    dst=cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "    \n",
    "    ret1, trackin_window=cv2.CamShift(dst,track_window,term_crit)\n",
    "    \n",
    "    pts=cv2.boxPoints(ret1)\n",
    "    pts=np.int0(pts)\n",
    "    img2=cv2.polylines(frame,[pts],True,(0,0,255),5)\n",
    "    \n",
    "    cv2.imshow('img',img2)\n",
    "    \n",
    "    k=cv2.waitKey(20) & 0xFF\n",
    "    \n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
